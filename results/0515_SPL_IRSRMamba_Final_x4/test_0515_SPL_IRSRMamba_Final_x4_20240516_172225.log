2024-05-16 17:22:25,444 INFO: 
  name: 0515_SPL_IRSRMamba_Final_x4
  model_type: MambaIRModel
  scale: 4
  num_gpu: 1
  manual_seed: 10
  datasets:[
    test_1:[
      name: results-A
      type: PairedImageDataset
      dataroot_gt: /home/usrs/hys/0010_Dataset/2024_0401_SPL/test/results-A/HR
      dataroot_lq: /home/usrs/hys/0010_Dataset/2024_0401_SPL/test/results-A/LR_bicubic/X4
      filename_tmpl: {}x4
      io_backend:[
        type: disk
      ]
      phase: test
      scale: 4
    ]
    test_2:[
      name: results-C
      type: PairedImageDataset
      dataroot_gt: /home/usrs/hys/0010_Dataset/2024_0401_SPL/test/results-C/HR
      dataroot_lq: /home/usrs/hys/0010_Dataset/2024_0401_SPL/test/results-C/LR_bicubic/X4
      filename_tmpl: {}x4
      io_backend:[
        type: disk
      ]
      phase: test
      scale: 4
    ]
  ]
  network_g:[
    type: IRSRMamba
    upscale: 4
    in_chans: 3
    img_size: 64
    window_size: 8
    img_range: 1.0
    d_state: 16
    depths: [6, 6, 6, 6, 6, 6]
    embed_dim: 180
    mlp_ratio: 2
    upsampler: pixelshuffle
    resi_connection: 1conv
  ]
  path:[
    pretrain_network_g: /home/usrs/hys/24-03.MambaIR/results/0510_SPL_IRSRMamba_Final_x4/IRSRMamba_final_x4.pth
    strict_load_g: True
    results_root: /var/autofs/home/hale/usrs/hys/IRSRMamba/results/0515_SPL_IRSRMamba_Final_x4
    log: /var/autofs/home/hale/usrs/hys/IRSRMamba/results/0515_SPL_IRSRMamba_Final_x4
    visualization: /var/autofs/home/hale/usrs/hys/IRSRMamba/results/0515_SPL_IRSRMamba_Final_x4/visualization
  ]
  val:[
    save_img: True
    suffix: None
    metrics:[
      psnr:[
        type: calculate_psnr
        crop_border: 4
        better: higher
        test_y_channel: True
      ]
      mse:[
        type: calculate_mse
        crop_border: 4
        better: lower
        test_y_channel: True
      ]
      ssim:[
        type: calculate_ssim
        crop_border: 4
        test_y_channel: True
      ]
    ]
  ]
  dist: False
  rank: 0
  world_size: 1
  auto_resume: False
  is_train: False

2024-05-16 17:22:25,446 INFO: Dataset [PairedImageDataset] - results-A is built.
2024-05-16 17:22:25,446 INFO: Number of test images in results-A: 22
2024-05-16 17:22:25,447 INFO: Dataset [PairedImageDataset] - results-C is built.
2024-05-16 17:22:25,448 INFO: Number of test images in results-C: 22
2024-05-16 17:22:30,828 INFO: Network [IRSRMamba] is created.
2024-05-16 17:22:31,523 INFO: Network: IRSRMamba, with parameters: 20,569,941
2024-05-16 17:22:31,523 INFO: IRSRMamba(
  (featureFusionmodule): FeatureFusionModule(
    (small_scale_extractor): SmallScaleFeatureExtractor(
      (conv3x3): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (large_scale_extractor): LargeScaleFeatureExtractor(
      (dwconv7x7): Conv2d(3, 3, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=3)
      (pointwise): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))
    )
    (wavelet_attention): WaveletAttention(
      (dwt): DWT()
      (channel_attention): ChannelAttentionModified(
        (max_pool): AdaptiveMaxPool2d(output_size=1)
        (fc1): Conv2d(3, 0, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (relu): ReLU()
        (fc2): Conv2d(0, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (feature_modulation): FeatureModulation(
      (mapping): FeatureMapping(
        (conv1): Conv2d(12, 6, kernel_size=(1, 1), stride=(1, 1))
        (silu): SiLU(inplace=True)
        (conv2): Conv2d(6, 3, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion_conv): Conv2d(6, 3, kernel_size=(1, 1), stride=(1, 1))
  )
  (conv_first): Conv2d(3, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (patch_embed): PatchEmbed(
    (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
  )
  (patch_unembed): PatchUnEmbed()
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): ResidualGroup(
      (residual_group): BasicLayer(
        dim=180, input_resolution=(64, 64), depth=6
        (blocks): ModuleList(
          (0): VSSBlock(
            (ln_1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (self_attention): SS2D(
              (in_proj): Linear(in_features=180, out_features=720, bias=False)
              (conv2d): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)
              (act): SiLU()
              (out_norm): LayerNorm((360,), eps=1e-05, elementwise_affine=True)
              (out_proj): Linear(in_features=360, out_features=180, bias=False)
            )
            (drop_path): DropPath(drop_prob=0.000)
            (conv_blk): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))
                    (4): Sigmoid()
                  )
                )
              )
            )
            (ln_2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          )
          (1): VSSBlock(
            (ln_1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (self_attention): SS2D(
              (in_proj): Linear(in_features=180, out_features=720, bias=False)
              (conv2d): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)
              (act): SiLU()
              (out_norm): LayerNorm((360,), eps=1e-05, elementwise_affine=True)
              (out_proj): Linear(in_features=360, out_features=180, bias=False)
            )
            (drop_path): DropPath(drop_prob=0.003)
            (conv_blk): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))
                    (4): Sigmoid()
                  )
                )
              )
            )
            (ln_2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          )
          (2): VSSBlock(
            (ln_1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (self_attention): SS2D(
              (in_proj): Linear(in_features=180, out_features=720, bias=False)
              (conv2d): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)
              (act): SiLU()
              (out_norm): LayerNorm((360,), eps=1e-05, elementwise_affine=True)
              (out_proj): Linear(in_features=360, out_features=180, bias=False)
            )
            (drop_path): DropPath(drop_prob=0.006)
            (conv_blk): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))
                    (4): Sigmoid()
                  )
                )
              )
            )
            (ln_2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          )
          (3): VSSBlock(
            (ln_1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (self_attention): SS2D(
              (in_proj): Linear(in_features=180, out_features=720, bias=False)
              (conv2d): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)
              (act): SiLU()
              (out_norm): LayerNorm((360,), eps=1e-05, elementwise_affine=True)
              (out_proj): Linear(in_features=360, out_features=180, bias=False)
            )
            (drop_path): DropPath(drop_prob=0.009)
            (conv_blk): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))
                    (4): Sigmoid()
                  )
                )
              )
            )
            (ln_2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          )
          (4): VSSBlock(
            (ln_1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (self_attention): SS2D(
              (in_proj): Linear(in_features=180, out_features=720, bias=False)
              (conv2d): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)
              (act): SiLU()
              (out_norm): LayerNorm((360,), eps=1e-05, elementwise_affine=True)
              (out_proj): Linear(in_features=360, out_features=180, bias=False)
            )
            (drop_path): DropPath(drop_prob=0.011)
            (conv_blk): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))
                    (4): Sigmoid()
                  )
                )
              )
            )
            (ln_2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          )
          (5): VSSBlock(
            (ln_1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (self_attention): SS2D(
              (in_proj): Linear(in_features=180, out_features=720, bias=False)
              (conv2d): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)
              (act): SiLU()
              (out_norm): LayerNorm((360,), eps=1e-05, elementwise_affine=True)
              (out_proj): Linear(in_features=360, out_features=180, bias=False)
            )
            (drop_path): DropPath(drop_prob=0.014)
            (conv_blk): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))
                    (4): Sigmoid()
                  )
                )
              )
            )
            (ln_2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (1): ResidualGroup(
      (residual_group): BasicLayer(
        dim=180, input_resolution=(64, 64), depth=6
        (blocks): ModuleList(
          (0): VSSBlock(
            (ln_1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (self_attention): SS2D(
              (in_proj): Linear(in_features=180, out_features=720, bias=False)
              (conv2d): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)
              (act): SiLU()
              (out_norm): LayerNorm((360,), eps=1e-05, elementwise_affine=True)
              (out_proj): Linear(in_features=360, out_features=180, bias=False)
            )
            (drop_path): DropPath(drop_prob=0.017)
            (conv_blk): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))
                    (4): Sigmoid()
                  )
                )
              )
            )
            (ln_2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          )
          (1): VSSBlock(
            (ln_1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (self_attention): SS2D(
              (in_proj): Linear(in_features=180, out_features=720, bias=False)
              (conv2d): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)
              (act): SiLU()
              (out_norm): LayerNorm((360,), eps=1e-05, elementwise_affine=True)
              (out_proj): Linear(in_features=360, out_features=180, bias=False)
            )
            (drop_path): DropPath(drop_prob=0.020)
            (conv_blk): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))
                    (4): Sigmoid()
                  )
                )
              )
            )
            (ln_2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          )
          (2): VSSBlock(
            (ln_1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (self_attention): SS2D(
              (in_proj): Linear(in_features=180, out_features=720, bias=False)
              (conv2d): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)
              (act): SiLU()
              (out_norm): LayerNorm((360,), eps=1e-05, elementwise_affine=True)
              (out_proj): Linear(in_features=360, out_features=180, bias=False)
            )
            (drop_path): DropPath(drop_prob=0.023)
            (conv_blk): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))
                    (4): Sigmoid()
                  )
                )
              )
            )
            (ln_2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          )
          (3): VSSBlock(
            (ln_1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (self_attention): SS2D(
              (in_proj): Linear(in_features=180, out_features=720, bias=False)
              (conv2d): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)
              (act): SiLU()
              (out_norm): LayerNorm((360,), eps=1e-05, elementwise_affine=True)
              (out_proj): Linear(in_features=360, out_features=180, bias=False)
            )
            (drop_path): DropPath(drop_prob=0.026)
            (conv_blk): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))
                    (4): Sigmoid()
                  )
                )
              )
            )
            (ln_2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          )
          (4): VSSBlock(
            (ln_1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (self_attention): SS2D(
              (in_proj): Linear(in_features=180, out_features=720, bias=False)
              (conv2d): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)
              (act): SiLU()
              (out_norm): LayerNorm((360,), eps=1e-05, elementwise_affine=True)
              (out_proj): Linear(in_features=360, out_features=180, bias=False)
            )
            (drop_path): DropPath(drop_prob=0.029)
            (conv_blk): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))
                    (4): Sigmoid()
                  )
                )
              )
            )
            (ln_2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          )
          (5): VSSBlock(
            (ln_1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (self_attention): SS2D(
              (in_proj): Linear(in_features=180, out_features=720, bias=False)
              (conv2d): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)
              (act): SiLU()
              (out_norm): LayerNorm((360,), eps=1e-05, elementwise_affine=True)
              (out_proj): Linear(in_features=360, out_features=180, bias=False)
            )
            (drop_path): DropPath(drop_prob=0.031)
            (conv_blk): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))
                    (4): Sigmoid()
                  )
                )
              )
            )
            (ln_2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (2): ResidualGroup(
      (residual_group): BasicLayer(
        dim=180, input_resolution=(64, 64), depth=6
        (blocks): ModuleList(
          (0): VSSBlock(
            (ln_1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (self_attention): SS2D(
              (in_proj): Linear(in_features=180, out_features=720, bias=False)
              (conv2d): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)
              (act): SiLU()
              (out_norm): LayerNorm((360,), eps=1e-05, elementwise_affine=True)
              (out_proj): Linear(in_features=360, out_features=180, bias=False)
            )
            (drop_path): DropPath(drop_prob=0.034)
            (conv_blk): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))
                    (4): Sigmoid()
                  )
                )
              )
            )
            (ln_2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          )
          (1): VSSBlock(
            (ln_1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (self_attention): SS2D(
              (in_proj): Linear(in_features=180, out_features=720, bias=False)
              (conv2d): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)
              (act): SiLU()
              (out_norm): LayerNorm((360,), eps=1e-05, elementwise_affine=True)
              (out_proj): Linear(in_features=360, out_features=180, bias=False)
            )
            (drop_path): DropPath(drop_prob=0.037)
            (conv_blk): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))
                    (4): Sigmoid()
                  )
                )
              )
            )
            (ln_2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          )
          (2): VSSBlock(
            (ln_1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (self_attention): SS2D(
              (in_proj): Linear(in_features=180, out_features=720, bias=False)
              (conv2d): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)
              (act): SiLU()
              (out_norm): LayerNorm((360,), eps=1e-05, elementwise_affine=True)
              (out_proj): Linear(in_features=360, out_features=180, bias=False)
            )
            (drop_path): DropPath(drop_prob=0.040)
            (conv_blk): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))
                    (4): Sigmoid()
                  )
                )
              )
            )
            (ln_2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          )
          (3): VSSBlock(
            (ln_1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (self_attention): SS2D(
              (in_proj): Linear(in_features=180, out_features=720, bias=False)
              (conv2d): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)
              (act): SiLU()
              (out_norm): LayerNorm((360,), eps=1e-05, elementwise_affine=True)
              (out_proj): Linear(in_features=360, out_features=180, bias=False)
            )
            (drop_path): DropPath(drop_prob=0.043)
            (conv_blk): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))
                    (4): Sigmoid()
                  )
                )
              )
            )
            (ln_2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          )
          (4): VSSBlock(
            (ln_1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (self_attention): SS2D(
              (in_proj): Linear(in_features=180, out_features=720, bias=False)
              (conv2d): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)
              (act): SiLU()
              (out_norm): LayerNorm((360,), eps=1e-05, elementwise_affine=True)
              (out_proj): Linear(in_features=360, out_features=180, bias=False)
            )
            (drop_path): DropPath(drop_prob=0.046)
            (conv_blk): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))
                    (4): Sigmoid()
                  )
                )
              )
            )
            (ln_2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          )
          (5): VSSBlock(
            (ln_1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (self_attention): SS2D(
              (in_proj): Linear(in_features=180, out_features=720, bias=False)
              (conv2d): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)
              (act): SiLU()
              (out_norm): LayerNorm((360,), eps=1e-05, elementwise_affine=True)
              (out_proj): Linear(in_features=360, out_features=180, bias=False)
            )
            (drop_path): DropPath(drop_prob=0.049)
            (conv_blk): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))
                    (4): Sigmoid()
                  )
                )
              )
            )
            (ln_2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (3): ResidualGroup(
      (residual_group): BasicLayer(
        dim=180, input_resolution=(64, 64), depth=6
        (blocks): ModuleList(
          (0): VSSBlock(
            (ln_1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (self_attention): SS2D(
              (in_proj): Linear(in_features=180, out_features=720, bias=False)
              (conv2d): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)
              (act): SiLU()
              (out_norm): LayerNorm((360,), eps=1e-05, elementwise_affine=True)
              (out_proj): Linear(in_features=360, out_features=180, bias=False)
            )
            (drop_path): DropPath(drop_prob=0.051)
            (conv_blk): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))
                    (4): Sigmoid()
                  )
                )
              )
            )
            (ln_2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          )
          (1): VSSBlock(
            (ln_1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (self_attention): SS2D(
              (in_proj): Linear(in_features=180, out_features=720, bias=False)
              (conv2d): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)
              (act): SiLU()
              (out_norm): LayerNorm((360,), eps=1e-05, elementwise_affine=True)
              (out_proj): Linear(in_features=360, out_features=180, bias=False)
            )
            (drop_path): DropPath(drop_prob=0.054)
            (conv_blk): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))
                    (4): Sigmoid()
                  )
                )
              )
            )
            (ln_2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          )
          (2): VSSBlock(
            (ln_1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (self_attention): SS2D(
              (in_proj): Linear(in_features=180, out_features=720, bias=False)
              (conv2d): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)
              (act): SiLU()
              (out_norm): LayerNorm((360,), eps=1e-05, elementwise_affine=True)
              (out_proj): Linear(in_features=360, out_features=180, bias=False)
            )
            (drop_path): DropPath(drop_prob=0.057)
            (conv_blk): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))
                    (4): Sigmoid()
                  )
                )
              )
            )
            (ln_2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          )
          (3): VSSBlock(
            (ln_1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (self_attention): SS2D(
              (in_proj): Linear(in_features=180, out_features=720, bias=False)
              (conv2d): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)
              (act): SiLU()
              (out_norm): LayerNorm((360,), eps=1e-05, elementwise_affine=True)
              (out_proj): Linear(in_features=360, out_features=180, bias=False)
            )
            (drop_path): DropPath(drop_prob=0.060)
            (conv_blk): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))
                    (4): Sigmoid()
                  )
                )
              )
            )
            (ln_2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          )
          (4): VSSBlock(
            (ln_1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (self_attention): SS2D(
              (in_proj): Linear(in_features=180, out_features=720, bias=False)
              (conv2d): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)
              (act): SiLU()
              (out_norm): LayerNorm((360,), eps=1e-05, elementwise_affine=True)
              (out_proj): Linear(in_features=360, out_features=180, bias=False)
            )
            (drop_path): DropPath(drop_prob=0.063)
            (conv_blk): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))
                    (4): Sigmoid()
                  )
                )
              )
            )
            (ln_2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          )
          (5): VSSBlock(
            (ln_1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (self_attention): SS2D(
              (in_proj): Linear(in_features=180, out_features=720, bias=False)
              (conv2d): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)
              (act): SiLU()
              (out_norm): LayerNorm((360,), eps=1e-05, elementwise_affine=True)
              (out_proj): Linear(in_features=360, out_features=180, bias=False)
            )
            (drop_path): DropPath(drop_prob=0.066)
            (conv_blk): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))
                    (4): Sigmoid()
                  )
                )
              )
            )
            (ln_2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (4): ResidualGroup(
      (residual_group): BasicLayer(
        dim=180, input_resolution=(64, 64), depth=6
        (blocks): ModuleList(
          (0): VSSBlock(
            (ln_1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (self_attention): SS2D(
              (in_proj): Linear(in_features=180, out_features=720, bias=False)
              (conv2d): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)
              (act): SiLU()
              (out_norm): LayerNorm((360,), eps=1e-05, elementwise_affine=True)
              (out_proj): Linear(in_features=360, out_features=180, bias=False)
            )
            (drop_path): DropPath(drop_prob=0.069)
            (conv_blk): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))
                    (4): Sigmoid()
                  )
                )
              )
            )
            (ln_2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          )
          (1): VSSBlock(
            (ln_1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (self_attention): SS2D(
              (in_proj): Linear(in_features=180, out_features=720, bias=False)
              (conv2d): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)
              (act): SiLU()
              (out_norm): LayerNorm((360,), eps=1e-05, elementwise_affine=True)
              (out_proj): Linear(in_features=360, out_features=180, bias=False)
            )
            (drop_path): DropPath(drop_prob=0.071)
            (conv_blk): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))
                    (4): Sigmoid()
                  )
                )
              )
            )
            (ln_2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          )
          (2): VSSBlock(
            (ln_1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (self_attention): SS2D(
              (in_proj): Linear(in_features=180, out_features=720, bias=False)
              (conv2d): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)
              (act): SiLU()
              (out_norm): LayerNorm((360,), eps=1e-05, elementwise_affine=True)
              (out_proj): Linear(in_features=360, out_features=180, bias=False)
            )
            (drop_path): DropPath(drop_prob=0.074)
            (conv_blk): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))
                    (4): Sigmoid()
                  )
                )
              )
            )
            (ln_2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          )
          (3): VSSBlock(
            (ln_1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (self_attention): SS2D(
              (in_proj): Linear(in_features=180, out_features=720, bias=False)
              (conv2d): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)
              (act): SiLU()
              (out_norm): LayerNorm((360,), eps=1e-05, elementwise_affine=True)
              (out_proj): Linear(in_features=360, out_features=180, bias=False)
            )
            (drop_path): DropPath(drop_prob=0.077)
            (conv_blk): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))
                    (4): Sigmoid()
                  )
                )
              )
            )
            (ln_2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          )
          (4): VSSBlock(
            (ln_1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (self_attention): SS2D(
              (in_proj): Linear(in_features=180, out_features=720, bias=False)
              (conv2d): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)
              (act): SiLU()
              (out_norm): LayerNorm((360,), eps=1e-05, elementwise_affine=True)
              (out_proj): Linear(in_features=360, out_features=180, bias=False)
            )
            (drop_path): DropPath(drop_prob=0.080)
            (conv_blk): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))
                    (4): Sigmoid()
                  )
                )
              )
            )
            (ln_2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          )
          (5): VSSBlock(
            (ln_1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (self_attention): SS2D(
              (in_proj): Linear(in_features=180, out_features=720, bias=False)
              (conv2d): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)
              (act): SiLU()
              (out_norm): LayerNorm((360,), eps=1e-05, elementwise_affine=True)
              (out_proj): Linear(in_features=360, out_features=180, bias=False)
            )
            (drop_path): DropPath(drop_prob=0.083)
            (conv_blk): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))
                    (4): Sigmoid()
                  )
                )
              )
            )
            (ln_2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (5): ResidualGroup(
      (residual_group): BasicLayer(
        dim=180, input_resolution=(64, 64), depth=6
        (blocks): ModuleList(
          (0): VSSBlock(
            (ln_1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (self_attention): SS2D(
              (in_proj): Linear(in_features=180, out_features=720, bias=False)
              (conv2d): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)
              (act): SiLU()
              (out_norm): LayerNorm((360,), eps=1e-05, elementwise_affine=True)
              (out_proj): Linear(in_features=360, out_features=180, bias=False)
            )
            (drop_path): DropPath(drop_prob=0.086)
            (conv_blk): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))
                    (4): Sigmoid()
                  )
                )
              )
            )
            (ln_2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          )
          (1): VSSBlock(
            (ln_1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (self_attention): SS2D(
              (in_proj): Linear(in_features=180, out_features=720, bias=False)
              (conv2d): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)
              (act): SiLU()
              (out_norm): LayerNorm((360,), eps=1e-05, elementwise_affine=True)
              (out_proj): Linear(in_features=360, out_features=180, bias=False)
            )
            (drop_path): DropPath(drop_prob=0.089)
            (conv_blk): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))
                    (4): Sigmoid()
                  )
                )
              )
            )
            (ln_2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          )
          (2): VSSBlock(
            (ln_1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (self_attention): SS2D(
              (in_proj): Linear(in_features=180, out_features=720, bias=False)
              (conv2d): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)
              (act): SiLU()
              (out_norm): LayerNorm((360,), eps=1e-05, elementwise_affine=True)
              (out_proj): Linear(in_features=360, out_features=180, bias=False)
            )
            (drop_path): DropPath(drop_prob=0.091)
            (conv_blk): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))
                    (4): Sigmoid()
                  )
                )
              )
            )
            (ln_2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          )
          (3): VSSBlock(
            (ln_1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (self_attention): SS2D(
              (in_proj): Linear(in_features=180, out_features=720, bias=False)
              (conv2d): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)
              (act): SiLU()
              (out_norm): LayerNorm((360,), eps=1e-05, elementwise_affine=True)
              (out_proj): Linear(in_features=360, out_features=180, bias=False)
            )
            (drop_path): DropPath(drop_prob=0.094)
            (conv_blk): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))
                    (4): Sigmoid()
                  )
                )
              )
            )
            (ln_2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          )
          (4): VSSBlock(
            (ln_1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (self_attention): SS2D(
              (in_proj): Linear(in_features=180, out_features=720, bias=False)
              (conv2d): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)
              (act): SiLU()
              (out_norm): LayerNorm((360,), eps=1e-05, elementwise_affine=True)
              (out_proj): Linear(in_features=360, out_features=180, bias=False)
            )
            (drop_path): DropPath(drop_prob=0.097)
            (conv_blk): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))
                    (4): Sigmoid()
                  )
                )
              )
            )
            (ln_2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          )
          (5): VSSBlock(
            (ln_1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (self_attention): SS2D(
              (in_proj): Linear(in_features=180, out_features=720, bias=False)
              (conv2d): Conv2d(360, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=360)
              (act): SiLU()
              (out_norm): LayerNorm((360,), eps=1e-05, elementwise_affine=True)
              (out_proj): Linear(in_features=360, out_features=180, bias=False)
            )
            (drop_path): DropPath(drop_prob=0.100)
            (conv_blk): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))
                    (4): Sigmoid()
                  )
                )
              )
            )
            (ln_2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
  )
  (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
  (conv_after_body): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv_before_upsample): Sequential(
    (0): Conv2d(180, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
  )
  (upsample): Upsample(
    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=2)
    (2): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): PixelShuffle(upscale_factor=2)
  )
  (conv_last): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)
2024-05-16 17:22:33,548 INFO: Loading IRSRMamba model from /home/usrs/hys/24-03.MambaIR/results/0510_SPL_IRSRMamba_Final_x4/IRSRMamba_final_x4.pth, with param key: [params].
2024-05-16 17:22:36,781 INFO: Model [MambaIRModel] is created.
2024-05-16 17:22:36,781 INFO: Testing results-A...
2024-05-16 17:23:09,752 INFO: Validation results-A
	 # psnr: 34.6501	Best: 34.6501 @ 0515_SPL_IRSRMamba_Final_x4 iter
	 # mse: 29.2505	Best: 29.2505 @ 0515_SPL_IRSRMamba_Final_x4 iter
	 # ssim: 0.8569	Best: 0.8569 @ 0515_SPL_IRSRMamba_Final_x4 iter

2024-05-16 17:23:09,754 INFO: Testing results-C...
2024-05-16 17:23:29,792 INFO: Validation results-C
	 # psnr: 35.2825	Best: 35.2825 @ 0515_SPL_IRSRMamba_Final_x4 iter
	 # mse: 23.3928	Best: 23.3928 @ 0515_SPL_IRSRMamba_Final_x4 iter
	 # ssim: 0.8738	Best: 0.8738 @ 0515_SPL_IRSRMamba_Final_x4 iter

